```{r message = FALSE}
library(tidyverse)
library(forecast)
```


# Importations des données 

Tout d'abord, on importe les données et on sélectionne les données concernant la France. 

```{r eval=FALSE, include=FALSE}
donnees <- read.csv("owid-covid-data.csv",sep=",",stringsAsFactors = T)
donnees_modif <- donnees |> 
  filter(iso_code == "FRA") |> 
  select(date,new_cases)
summary(donnees_modif)

write.table(x = donnees_modif, file = "covid_france.csv", sep = ",")
```


```{r}
donnees_fr <- read.csv("covid_france.csv",sep=",")
summary(donnees_fr)
```
Les données ci-dessus comprennent une variable temporelle et une variable caractérisée par un enregistrement journalier des nouveaux cas de Covid-19 en France. 

```{r}
min(donnees_fr$date)
max(donnees_fr$date)
```
Grâce à cette étape, nous pouvons observer que notre série temporelle débute le 1er Mars 2020 et se termine le 19 Avril 2023. Notre étude a donc une plage d'environ de 3 ans.

## Transformation des données en série temporelle

Premièrement, nous allons transformer nos données en séries temporelles pour pouvoir réaliser notre analyse. 

```{r}
ts_donnees_fr <- ts(donnees_fr$new_cases,start = c(2020,1,3), frequency = 365)
# class(ts_donnees_fr)
```

# Première partie 

```{r}
plot(ts_donnees_fr)
```
Ce premier graphique nous montre une hausse brutale des nouveaux cas de covids en 2022. Afin de pouvoir continuer notre analyse de façon cohérente, nous allons diviser notre série en 3 parties : avant, pendant et après ce choc en 2022.  

## Division de notre série 

Nous décidons de créer trois sous-séries de notre série initiale afin de pouvoir réaliser le traitement des données. Notre objectif est d'isoler le cas particulier de l'année 2022 pour avoir une étude correcte.

```{r}
serie1 <- donnees_fr |> 
  filter(date<="2021-12-22")
# serie1
ts_serie1 <- ts(serie1$new_cases,start = c(2020,1,3), frequency = 365)



serie2 <- donnees_fr |> 
  filter(date>"2021-12-22", date<="2023-01-05")
# serie2

ts_serie2 <- ts(serie2$new_cases,start = c(2021,31,12), frequency = 365)



serie3 <- donnees_fr |> 
  filter(date>"2023-01-05")

ts_serie3 <- ts(serie3$new_cases,start = c(2023,2,5), frequency = 365)
```

Nous avons choisi de scinder notre série en trois périodes : 
- avant le 22 Décembre 2021
- entre le 23 Décembre 2021 et le 5 Janvier 2023
- après le 6 Janvier 2023

Nous pouvons maintenant les visualiser : 

```{r}
plot(ts_serie1,main="Nouveaux cas de covid-19 en France entre 2020 et 2022")
```

```{r}
plot(ts_serie2,main="Nouveaux cas de covid-19 en France entre 2022 et 2023")
```

```{r}
plot(ts_serie3,main="Nouveaux cas de covid-19 en France en 2023")
```

Grâce à cette division, nous allons pouvoir étudier chaque sous-série pertinemment. 

## Analyse de la première sous-série

Nous avons décidé de nous focaliser sur la première sous-série. \
Ce choix est expliqué grâce à notre connaissance des évènements durant cette année particulière. En effet, les confinements ont pu avoir des conséquences sur notre série et nos données.
Notre étude commence donc le 1er Mars 2020 et s'étend jusqu'au 22 décembre 2021.

Pour rappel, notre série présente une tendance à la hausse comme le montre le graphique ci-dessous. Elle présente aussi une saisonnalité, mais elle n'est pas régulière. En effet, les différentes hausses de nouveaux cas de covid dépendent des confinements et des mesures sanitaires mises en place.

```{r}
autoplot(ts_serie1)+
  geom_smooth(method = lm,color="blue")+
  ggtitle("Nouveaux cas de covids en France entre 2020 et 2022")
```


On va d'abord chercher à décrire notre série grâce à des indicateurs descriptifs simples.

```{r}
mean(ts_serie1)
```
Entre le 1er Mars 2020 et le 22 Décembre 2022, la moyenne des nouveaux cas de covids par jour était de 11 763 cas en France.

```{r}
ts_serie1 |> 
  ggtsdisplay(plot.type = "scatter",smooth=FALSE)
```
Nous pouvons faire quelques observations sur le graphique de l'ACF. Ce graphique nous permet de détecter une structure de corrélation du réseau. Dans notre cas, plusieurs autocorrélations présentent des valeurs significativement non nulles, ce qui signifie que la série chronologique n'est pas aléatoire. 


### Décomposition de la série

```{r}
# mod_stl_add <- stl(ts_serie1, s.window = "periodic")
```
```{r}
# serie1 |>  ggplot() +
#   geom_line(aes(x = date, y=new_cases, color="Xt")) +
#   geom_line(aes(x=date, y=trend+seasonal, color="mt+st")) + 
#   geom_line(aes(x=date, y=trend, color="mt")) +
#   scale_color_manual(values = c("red", "blue", "black")) +
#   theme(legend.position = c(0.8, 0.08), legend.direction = "horizontal") +
#   labs(colour = "Modele") + 
#   ggtitle("Modèle additif") +
#   xlab("Années") + 
#   ylab("Nombre de cas de varicelles") + theme_minimal()
```




### Stationnarité 

**Retrait de la saisonnalité** 

Ensuite, nous cherchons à nous ramener à une série stationnaire. Pour cela, nous devons éliminer la tendance linéaire. Afin de stationariser notre série, nous allons utiliser l'opérateur diff. Nous allons donc construire un filtre permettant de construire notre analyse. \

Tout d'abord, nous avons décider de ne pas transformer notre série en logarithme. Celle-ci nous permettrait de réduire sa variance mais puisque la série présente des valeurs nulles, cette transformation n'est pas pertinente. \

Nous allons donc différencier la série : 

```{r}
ndiffs(ts_serie1) # On nous conseille de différencier la série 1 fois

serie_lissee <- ts_serie1 |> 
  diff(lag=1)

ndiffs(serie_lissee) # la série a été différencié comme il faut
```
Puisque l'on différencie une seule fois, la variance augmente mais reste plus faible que si l'on avait différencié 3 ou 4 fois par exemple.

```{r}
serie_lissee |> 
  ggtsdisplay(plot.type = "scatter",smooth=FALSE)
```

Grâce à cette méthode, nous pouvons faire plusieurs constats :
- **Le chronogramme** : 
Notre différenciation nous permet de stationariser notre série et supprimer la tendance. Nous pouvons donc émettre l'hypothèse d'un modèle polynomial. 

- **L'ACF** :
L'auto-corrélation décroit car on fait des moyennes sur de moins en moins de valeurs. Nous n'observons pas de saisonnalité dans notre série.

- **Corrélation** :
Nous ne pouvons pas observer de réelle périodicité. 

### Détection de l'autocorrélation partielle

Afin de détecter la présence d'autocorrélation partielle, nous allons utiliser la fonction pacf. Elle nous permet de mesurer l'aurocorrélation d'un signal pour un décalage k "indépendamment" des autocorrélations pour les décalages inférieurs. \
Nous avons choisi d'utiliser cette fonction car le corrélogramme produit par la fonction ggdisplay montre des autocorrélations fortes à répétition.


```{r}
pacf(serie_lissee)
```






### Estimation du modèle

Nous allons essayer de choisir le meilleur modèle afin d'estimer notre série.

# ARIMA ?
# ARMA ?

```{r}
# auto.arima(serie_lissee,d=1,D=1,stepwise = FALSE,approximation=FALSE,trace=TRUE)
```


### Estimation par régression linéaire (MCO)

```{r}
t <- 1:length(ts_serie1)
x <- outer(t,1:6)*(pi/6)
df <- data.frame(ts_serie1,t,cos(x),sin(x[,-6])) 
ts_serie1_lm <- lm(data=df,ts_serie1~.)

summary(ts_serie1_lm)
```








